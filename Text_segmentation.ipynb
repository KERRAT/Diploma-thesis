{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "image_folder = \"Ukr\"\n",
    "east_path = \"text_detection/frozen_east_text_detection.pb\"\n",
    "min_confidence = 0.5\n",
    "width = 320\n",
    "height = 320\n",
    "\n",
    "output_folder = \"tmp\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "  \n",
    "  \n",
    "\n",
    "def noise_removal(image):\n",
    "  import numpy as np\n",
    "  kernel = np.ones((1,1),np.uint8)\n",
    "  image = cv2.dilate(image, kernel, iterations=1)\n",
    "  kernel = np.ones((1,1),np.uint8)\n",
    "  image = cv2.erode(image, kernel, iterations=1)    \n",
    "  image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel, iterations=4)\n",
    "  image = cv2.medianBlur(image, 3)\n",
    "  return (image)\n",
    "\n",
    "def illumination_removal(image):\n",
    "  se=cv2.getStructuringElement(cv2.MORPH_RECT , (8,8))\n",
    "  bg=cv2.morphologyEx(image, cv2.MORPH_DILATE, se)\n",
    "  out_gray=cv2.divide(image, bg, scale=255)\n",
    "  return out_gray\n",
    "\n",
    "def getSkewAngle(cvImage) -> float:\n",
    "  # Prep image, copy, convert to gray scale, blur, and threshold\n",
    "  newImage = cvImage.copy()\n",
    "  gray = cv2.cvtColor(newImage, cv2.COLOR_BGR2GRAY)\n",
    "  blur = cv2.GaussianBlur(gray, (9, 9), 0)\n",
    "  thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "  # Apply dilate to merge text into meaningful lines/paragraphs.\n",
    "  # Use larger kernel on X axis to merge characters into single line, cancelling out any spaces.\n",
    "  # But use smaller kernel on Y axis to separate between different blocks of text\n",
    "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))\n",
    "  dilate = cv2.dilate(thresh, kernel, iterations=2)\n",
    "\n",
    "  # Find all contours\n",
    "  contours, hierarchy = cv2.findContours(dilate, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  contours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "  for c in contours:\n",
    "      rect = cv2.boundingRect(c)\n",
    "      x,y,w,h = rect\n",
    "      cv2.rectangle(newImage,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "  # Find largest contour and surround in min area box\n",
    "  largestContour = contours[0]\n",
    "  print (len(contours))\n",
    "  minAreaRect = cv2.minAreaRect(largestContour)\n",
    "  cv2.imwrite(\"temp/boxes.jpg\", newImage)\n",
    "  # Determine the angle. Convert it to the value that was originally used to obtain skewed image\n",
    "  angle = minAreaRect[-1]\n",
    "  if angle < -45:\n",
    "      angle = 90 + angle\n",
    "  return -1.0 * angle\n",
    "# Rotate the image around its center\n",
    "def rotateImage(cvImage, angle: float):\n",
    "  newImage = cvImage.copy()\n",
    "  (h, w) = newImage.shape[:2]\n",
    "  center = (w // 2, h // 2)\n",
    "  M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "  newImage = cv2.warpAffine(newImage, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "  return newImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_img(img):\n",
    "  # convert to grayscale\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  # blur\n",
    "  blur = cv2.GaussianBlur(gray, (0,0), sigmaX=33, sigmaY=33)\n",
    "\n",
    "  # divide\n",
    "  divide = cv2.divide(gray, blur, scale=255)\n",
    "\n",
    "  # otsu threshold\n",
    "  thresh = cv2.threshold(divide, 160, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "\n",
    "  # apply morphology\n",
    "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,1))\n",
    "  morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "  rgb_img = cv2.cvtColor(morph, cv2.COLOR_GRAY2RGB)\n",
    "  return rgb_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_letters(image, word_image):\n",
    "    thresh = cv2.threshold(word_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 25))\n",
    "    detected_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel, iterations=1)\n",
    "    \n",
    "    cv2.imshow('Thresh', thresh)\n",
    "    cv2.imshow('Detected Lines', detected_lines)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    cnts = cv2.findContours(detected_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    letters = []\n",
    "    for c in cnts:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        letter = word_image[y:y+h, x:x+w]\n",
    "        letters.append((x, y, w, h, letter))\n",
    "\n",
    "    return letters if letters else [(0, 0, 0, 0, word_image)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Ukr\\Franko_page.jpg\n",
      "x1= 0 , x2= 0 , Diff=  0\n",
      "x1= 0 , x2= 10 , Diff=  10\n",
      "x1= 10 , x2= 22 , Diff=  12\n",
      "x1= 22 , x2= 51 , Diff=  29\n",
      "x1= 51 , x2= 79 , Diff=  28\n",
      "x1= 79 , x2= 107 , Diff=  28\n",
      "x1= 107 , x2= 135 , Diff=  28\n",
      "x1= 135 , x2= 163 , Diff=  28\n",
      "x1= 163 , x2= 195 , Diff=  32\n",
      "x1= 195 , x2= 236 , Diff=  41\n",
      "x1= 236 , x2= 264 , Diff=  28\n",
      "x1= 264 , x2= 292 , Diff=  28\n",
      "x1= 292 , x2= 320 , Diff=  28\n",
      "x1= 320 , x2= 348 , Diff=  28\n",
      "x1= 348 , x2= 376 , Diff=  28\n",
      "x1= 376 , x2= 404 , Diff=  28\n",
      "x1= 404 , x2= 432 , Diff=  28\n",
      "x1= 432 , x2= 459 , Diff=  27\n",
      "x1= 459 , x2= 499 , Diff=  40\n",
      "x1= 499 , x2= 532 , Diff=  33\n",
      "x1= 532 , x2= 560 , Diff=  28\n",
      "x1= 560 , x2= 587 , Diff=  27\n",
      "x1= 587 , x2= 615 , Diff=  28\n",
      "x1= 615 , x2= 642 , Diff=  27\n",
      "x1= 642 , x2= 671 , Diff=  29\n",
      "x1= 671 , x2= 722 , Diff=  51\n",
      "Processing Ukr\\Kortlyarevskiy_sun_page.jpg\n",
      "x1= 0 , x2= 0 , Diff=  0\n",
      "x1= 0 , x2= 18 , Diff=  18\n",
      "x1= 18 , x2= 26 , Diff=  8\n",
      "x1= 26 , x2= 30 , Diff=  4\n",
      "x1= 30 , x2= 35 , Diff=  5\n",
      "x1= 35 , x2= 71 , Diff=  36\n",
      "x1= 71 , x2= 103 , Diff=  32\n",
      "x1= 103 , x2= 135 , Diff=  32\n",
      "x1= 135 , x2= 167 , Diff=  32\n",
      "x1= 167 , x2= 199 , Diff=  32\n",
      "x1= 199 , x2= 231 , Diff=  32\n",
      "x1= 231 , x2= 263 , Diff=  32\n",
      "x1= 263 , x2= 296 , Diff=  33\n",
      "x1= 296 , x2= 329 , Diff=  33\n",
      "x1= 329 , x2= 360 , Diff=  31\n",
      "x1= 360 , x2= 393 , Diff=  33\n",
      "x1= 393 , x2= 424 , Diff=  31\n",
      "x1= 424 , x2= 458 , Diff=  34\n",
      "x1= 458 , x2= 488 , Diff=  30\n",
      "x1= 488 , x2= 520 , Diff=  32\n",
      "x1= 520 , x2= 552 , Diff=  32\n",
      "x1= 552 , x2= 584 , Diff=  32\n",
      "x1= 584 , x2= 620 , Diff=  36\n",
      "x1= 620 , x2= 713 , Diff=  93\n",
      "Processing Ukr\\Zahar_Berkyt_page.jpg\n",
      "x1= 0 , x2= 0 , Diff=  0\n",
      "x1= 0 , x2= 14 , Diff=  14\n",
      "x1= 14 , x2= 37 , Diff=  23\n",
      "x1= 37 , x2= 55 , Diff=  18\n",
      "x1= 55 , x2= 81 , Diff=  26\n",
      "x1= 81 , x2= 97 , Diff=  16\n",
      "x1= 97 , x2= 116 , Diff=  19\n",
      "x1= 116 , x2= 127 , Diff=  11\n",
      "x1= 127 , x2= 146 , Diff=  19\n",
      "x1= 146 , x2= 162 , Diff=  16\n",
      "x1= 162 , x2= 178 , Diff=  16\n",
      "x1= 178 , x2= 195 , Diff=  17\n",
      "x1= 195 , x2= 211 , Diff=  16\n",
      "x1= 211 , x2= 227 , Diff=  16\n",
      "x1= 227 , x2= 244 , Diff=  17\n",
      "x1= 244 , x2= 260 , Diff=  16\n",
      "x1= 260 , x2= 276 , Diff=  16\n",
      "x1= 276 , x2= 293 , Diff=  17\n",
      "x1= 293 , x2= 309 , Diff=  16\n",
      "x1= 309 , x2= 325 , Diff=  16\n",
      "x1= 325 , x2= 342 , Diff=  17\n",
      "x1= 342 , x2= 358 , Diff=  16\n",
      "x1= 358 , x2= 374 , Diff=  16\n",
      "x1= 374 , x2= 391 , Diff=  17\n",
      "x1= 391 , x2= 407 , Diff=  16\n",
      "x1= 407 , x2= 423 , Diff=  16\n",
      "x1= 423 , x2= 440 , Diff=  17\n",
      "x1= 440 , x2= 456 , Diff=  16\n",
      "x1= 456 , x2= 473 , Diff=  17\n",
      "x1= 473 , x2= 487 , Diff=  14\n",
      "x1= 487 , x2= 504 , Diff=  17\n",
      "x1= 504 , x2= 521 , Diff=  17\n",
      "x1= 521 , x2= 537 , Diff=  16\n",
      "x1= 537 , x2= 553 , Diff=  16\n",
      "x1= 553 , x2= 569 , Diff=  16\n",
      "x1= 569 , x2= 592 , Diff=  23\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "from opencv_text_detection.text_detection import text_detection\n",
    "\n",
    "from Page_to_lines import get_lines, display_lines\n",
    "\n",
    "for file_name in os.listdir(image_folder):\n",
    "  if file_name.endswith(\".jpg\") or file_name.endswith(\".png\"):\n",
    "    image_path = os.path.join(image_folder, file_name)\n",
    "    print(f\"Processing {image_path}\")\n",
    "\n",
    "    if \"_page\" in file_name:\n",
    "        image = cv2.imread(image_path)\n",
    "        lines = get_lines(image_path, kernel_size = 17, sigma=2, theta=9, smooth_window_len=4, threshold=0.3, peak_min_distance=2)\n",
    "\n",
    "        # Create a folder for the current image\n",
    "        current_image_folder = os.path.join(output_folder, file_name[:-4])\n",
    "        if not os.path.exists(current_image_folder):\n",
    "            os.makedirs(current_image_folder)\n",
    "\n",
    "        # Process each line and save it in the folder\n",
    "        for idx, line in enumerate(lines):\n",
    "            if not line.size == 0:  # Check if the line is not empty\n",
    "                line = cv2.cvtColor(line, cv2.COLOR_GRAY2RGB)\n",
    "                output_file = os.path.join(current_image_folder, f\"line_{idx}.jpg\")\n",
    "                cv2.imwrite(output_file, line)\n",
    "    else:\n",
    "        data, result_img = text_detection(image_path, east_path, min_confidence, width, height)\n",
    "        output_file = os.path.join(output_folder, file_name)\n",
    "        cv2.imwrite(output_file, result_img)\n",
    "\n",
    "print(\"Processing completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
