{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "image_folder = \"Ukr\"\n",
    "east_path = \"text_detection/frozen_east_text_detection.pb\"\n",
    "min_confidence = 0.5\n",
    "width = 320\n",
    "height = 320\n",
    "\n",
    "output_folder = \"tmp\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "  \n",
    "  \n",
    "\n",
    "def noise_removal(image):\n",
    "  import numpy as np\n",
    "  kernel = np.ones((1,1),np.uint8)\n",
    "  image = cv2.dilate(image, kernel, iterations=1)\n",
    "  kernel = np.ones((1,1),np.uint8)\n",
    "  image = cv2.erode(image, kernel, iterations=1)    \n",
    "  image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel, iterations=4)\n",
    "  image = cv2.medianBlur(image, 3)\n",
    "  return (image)\n",
    "\n",
    "def illumination_removal(image):\n",
    "  se=cv2.getStructuringElement(cv2.MORPH_RECT , (8,8))\n",
    "  bg=cv2.morphologyEx(image, cv2.MORPH_DILATE, se)\n",
    "  out_gray=cv2.divide(image, bg, scale=255)\n",
    "  return out_gray\n",
    "\n",
    "def getSkewAngle(cvImage) -> float:\n",
    "  # Prep image, copy, convert to gray scale, blur, and threshold\n",
    "  newImage = cvImage.copy()\n",
    "  gray = cv2.cvtColor(newImage, cv2.COLOR_BGR2GRAY)\n",
    "  blur = cv2.GaussianBlur(gray, (9, 9), 0)\n",
    "  thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "  # Apply dilate to merge text into meaningful lines/paragraphs.\n",
    "  # Use larger kernel on X axis to merge characters into single line, cancelling out any spaces.\n",
    "  # But use smaller kernel on Y axis to separate between different blocks of text\n",
    "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))\n",
    "  dilate = cv2.dilate(thresh, kernel, iterations=2)\n",
    "\n",
    "  # Find all contours\n",
    "  contours, hierarchy = cv2.findContours(dilate, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  contours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "  for c in contours:\n",
    "      rect = cv2.boundingRect(c)\n",
    "      x,y,w,h = rect\n",
    "      cv2.rectangle(newImage,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "  # Find largest contour and surround in min area box\n",
    "  largestContour = contours[0]\n",
    "  print (len(contours))\n",
    "  minAreaRect = cv2.minAreaRect(largestContour)\n",
    "  cv2.imwrite(\"temp/boxes.jpg\", newImage)\n",
    "  # Determine the angle. Convert it to the value that was originally used to obtain skewed image\n",
    "  angle = minAreaRect[-1]\n",
    "  if angle < -45:\n",
    "      angle = 90 + angle\n",
    "  return -1.0 * angle\n",
    "# Rotate the image around its center\n",
    "def rotateImage(cvImage, angle: float):\n",
    "  newImage = cvImage.copy()\n",
    "  (h, w) = newImage.shape[:2]\n",
    "  center = (w // 2, h // 2)\n",
    "  M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "  newImage = cv2.warpAffine(newImage, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "  return newImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_border(image):\n",
    "    top, bottom, left, right = 1, 1, 1, 1\n",
    "    image_without_borders = image[top:-bottom, left:-right]\n",
    "\n",
    "    image_with_border = cv2.copyMakeBorder(image_without_borders, 1, 1, 1, 1, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
    "    return image_with_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_image(image):\n",
    "    if image is None or not isinstance(image, np.ndarray) or len(image.shape) < 2:\n",
    "        raise ValueError(\"Invalid input image.\")\n",
    "\n",
    "    if len(image.shape) == 2 or image.shape[2] == 1:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    elif image.shape[2] > 3:\n",
    "        image = image[:, :, :3]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def fully_clear_background(image):\n",
    "    formated = format_image(image)\n",
    "\n",
    "    image_with_border = clear_border(formated)\n",
    "\n",
    "    gray_image = cv2.cvtColor(image_with_border, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (3, 3), 0)\n",
    "\n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 27, 50)\n",
    "    \n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def is_line_empty(line, threshold=0.03, gray_threshold=130):\n",
    "    \"\"\"\n",
    "    Determine if a line contains text based on the number of non-white pixels.\n",
    "\n",
    "    Args:\n",
    "    line (numpy.ndarray): Image of the line.\n",
    "    threshold (float): Threshold for the proportion of non-white pixels to consider a line as empty. Default is 0.01 (1%).\n",
    "    gray_threshold (int): Gray level threshold to consider a pixel as non-white. Default is 200.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the line is empty, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    non_white_pixels = np.count_nonzero(line < gray_threshold)\n",
    "    total_pixels = line.size\n",
    "\n",
    "    if non_white_pixels / total_pixels < threshold:\n",
    "        print('true:', non_white_pixels / total_pixels)\n",
    "        return True\n",
    "    else:\n",
    "        print('false:', non_white_pixels / total_pixels)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import contours\n",
    "\n",
    "def segment_words(image, p_image, file_name, line_number):\n",
    "    converted = cv2.bitwise_not(p_image)\n",
    "    \n",
    "    blurred_image = cv2.GaussianBlur(converted, (5, 5), 0)\n",
    "\n",
    "    # Apply morphological dilation to connect words\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 12))\n",
    "    dilated = cv2.dilate(blurred_image, kernel, iterations=1)\n",
    "\n",
    "    cnts = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    \n",
    "\n",
    "    words_images = []\n",
    "    if len(cnts) > 0:\n",
    "        cnts, _ = contours.sort_contours(cnts, method=\"left-to-right\")\n",
    "        \n",
    "        for c in cnts:\n",
    "            area = cv2.contourArea(c)\n",
    "            if area > 10:\n",
    "                x, y, w, h = cv2.boundingRect(c)\n",
    "                ROI = image[y:y+h, x:x+w]\n",
    "                words_images.append(ROI)\n",
    "\n",
    "    return words_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def extract_letters(word_image):\n",
    "    no_border = clear_border(word_image)\n",
    "    _, otsu_threshold = cv2.threshold(no_border, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Apply morphological dilation to connect words\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 7))\n",
    "    dilated = cv2.dilate(otsu_threshold, kernel, iterations=1)\n",
    "    \n",
    "    # Apply morphological erosion to separate connected letters\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 4))  # Increase kernel size\n",
    "    eroded = cv2.erode(dilated, kernel, iterations=1)\n",
    "    \n",
    "    contours, _ = cv2.findContours(eroded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    image_copy = word_image.copy()\n",
    "    image_copy = cv2.cvtColor(image_copy, cv2.COLOR_GRAY2BGR)\n",
    "    letters = []\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if h > 0 and w > 0:\n",
    "            # Draw rectangle around the letter on the word image\n",
    "            cv2.rectangle(image_copy, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            letter = word_image[y:y+h, x:x+w]\n",
    "            letters.append(letter)\n",
    "\n",
    "    return letters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Ukr\\Franko_page.jpg\n",
      "x1= 0 , x2= 0 , Diff=  0\n",
      "x1= 0 , x2= 10 , Diff=  10\n",
      "x1= 10 , x2= 22 , Diff=  12\n",
      "x1= 22 , x2= 51 , Diff=  29\n",
      "x1= 51 , x2= 79 , Diff=  28\n",
      "x1= 79 , x2= 107 , Diff=  28\n",
      "x1= 107 , x2= 135 , Diff=  28\n",
      "x1= 135 , x2= 163 , Diff=  28\n",
      "x1= 163 , x2= 195 , Diff=  32\n",
      "x1= 195 , x2= 236 , Diff=  41\n",
      "x1= 236 , x2= 264 , Diff=  28\n",
      "x1= 264 , x2= 292 , Diff=  28\n",
      "x1= 292 , x2= 320 , Diff=  28\n",
      "x1= 320 , x2= 348 , Diff=  28\n",
      "x1= 348 , x2= 376 , Diff=  28\n",
      "x1= 376 , x2= 404 , Diff=  28\n",
      "x1= 404 , x2= 432 , Diff=  28\n",
      "x1= 432 , x2= 459 , Diff=  27\n",
      "x1= 459 , x2= 499 , Diff=  40\n",
      "x1= 499 , x2= 532 , Diff=  33\n",
      "x1= 532 , x2= 560 , Diff=  28\n",
      "x1= 560 , x2= 587 , Diff=  27\n",
      "x1= 587 , x2= 615 , Diff=  28\n",
      "x1= 615 , x2= 642 , Diff=  27\n",
      "x1= 642 , x2= 671 , Diff=  29\n",
      "x1= 671 , x2= 722 , Diff=  51\n",
      "true: 0.0\n",
      "true: 0.0\n",
      "false: 0.046130560673861544\n",
      "false: 0.05234460196292257\n",
      "false: 0.07163304252998909\n",
      "false: 0.051731188658669575\n",
      "false: 0.05111777535441658\n",
      "false: 0.04276001908396947\n",
      "false: 0.03579407931483895\n",
      "false: 0.07211014176663032\n",
      "false: 0.0679525627044711\n",
      "false: 0.0570474372955289\n",
      "false: 0.06318157033805889\n",
      "false: 0.07292802617230099\n",
      "false: 0.06277262813522355\n",
      "false: 0.05425299890948746\n",
      "false: 0.05195080576759966\n",
      "false: 0.040744274809160305\n",
      "false: 0.05117973629424011\n",
      "false: 0.05507088331515812\n",
      "false: 0.05774667797568561\n",
      "false: 0.061205016357688116\n",
      "false: 0.05626236923946848\n",
      "false: 0.04237957357199263\n",
      "true: 0.013321359077982337\n",
      "Processing Ukr\\Kortlyarevskiy_sun_page.jpg\n",
      "x1= 0 , x2= 0 , Diff=  0\n",
      "x1= 0 , x2= 18 , Diff=  18\n",
      "x1= 18 , x2= 26 , Diff=  8\n",
      "x1= 26 , x2= 30 , Diff=  4\n",
      "x1= 30 , x2= 35 , Diff=  5\n",
      "x1= 35 , x2= 71 , Diff=  36\n",
      "x1= 71 , x2= 103 , Diff=  32\n",
      "x1= 103 , x2= 135 , Diff=  32\n",
      "x1= 135 , x2= 167 , Diff=  32\n",
      "x1= 167 , x2= 199 , Diff=  32\n",
      "x1= 199 , x2= 231 , Diff=  32\n",
      "x1= 231 , x2= 263 , Diff=  32\n",
      "x1= 263 , x2= 296 , Diff=  33\n",
      "x1= 296 , x2= 329 , Diff=  33\n",
      "x1= 329 , x2= 360 , Diff=  31\n",
      "x1= 360 , x2= 393 , Diff=  33\n",
      "x1= 393 , x2= 424 , Diff=  31\n",
      "x1= 424 , x2= 458 , Diff=  34\n",
      "x1= 458 , x2= 488 , Diff=  30\n",
      "x1= 488 , x2= 520 , Diff=  32\n",
      "x1= 520 , x2= 552 , Diff=  32\n",
      "x1= 552 , x2= 584 , Diff=  32\n",
      "x1= 584 , x2= 620 , Diff=  36\n",
      "x1= 620 , x2= 713 , Diff=  93\n",
      "true: 0.0\n",
      "true: 0.0015625\n",
      "true: 0.0\n",
      "false: 0.03770833333333334\n",
      "false: 0.09435763888888889\n",
      "false: 0.12483723958333333\n",
      "false: 0.10406901041666666\n",
      "false: 0.10911458333333333\n",
      "false: 0.11767578125\n",
      "false: 0.11158854166666667\n",
      "false: 0.11276041666666667\n",
      "false: 0.09908459595959596\n",
      "false: 0.10587121212121212\n",
      "false: 0.10950940860215054\n",
      "false: 0.09952651515151516\n",
      "false: 0.10981182795698925\n",
      "false: 0.09424019607843137\n",
      "false: 0.10291666666666667\n",
      "false: 0.10413411458333334\n",
      "false: 0.09736328125\n",
      "false: 0.09661458333333334\n",
      "false: 0.04635416666666667\n",
      "true: 2.2401433691756272e-05\n",
      "Processing Ukr\\Zahar_Berkyt_page.jpg\n",
      "x1= 0 , x2= 0 , Diff=  0\n",
      "x1= 0 , x2= 14 , Diff=  14\n",
      "x1= 14 , x2= 37 , Diff=  23\n",
      "x1= 37 , x2= 55 , Diff=  18\n",
      "x1= 55 , x2= 81 , Diff=  26\n",
      "x1= 81 , x2= 97 , Diff=  16\n",
      "x1= 97 , x2= 116 , Diff=  19\n",
      "x1= 116 , x2= 127 , Diff=  11\n",
      "x1= 127 , x2= 146 , Diff=  19\n",
      "x1= 146 , x2= 162 , Diff=  16\n",
      "x1= 162 , x2= 178 , Diff=  16\n",
      "x1= 178 , x2= 195 , Diff=  17\n",
      "x1= 195 , x2= 211 , Diff=  16\n",
      "x1= 211 , x2= 227 , Diff=  16\n",
      "x1= 227 , x2= 244 , Diff=  17\n",
      "x1= 244 , x2= 260 , Diff=  16\n",
      "x1= 260 , x2= 276 , Diff=  16\n",
      "x1= 276 , x2= 293 , Diff=  17\n",
      "x1= 293 , x2= 309 , Diff=  16\n",
      "x1= 309 , x2= 325 , Diff=  16\n",
      "x1= 325 , x2= 342 , Diff=  17\n",
      "x1= 342 , x2= 358 , Diff=  16\n",
      "x1= 358 , x2= 374 , Diff=  16\n",
      "x1= 374 , x2= 391 , Diff=  17\n",
      "x1= 391 , x2= 407 , Diff=  16\n",
      "x1= 407 , x2= 423 , Diff=  16\n",
      "x1= 423 , x2= 440 , Diff=  17\n",
      "x1= 440 , x2= 456 , Diff=  16\n",
      "x1= 456 , x2= 473 , Diff=  17\n",
      "x1= 473 , x2= 487 , Diff=  14\n",
      "x1= 487 , x2= 504 , Diff=  17\n",
      "x1= 504 , x2= 521 , Diff=  17\n",
      "x1= 521 , x2= 537 , Diff=  16\n",
      "x1= 537 , x2= 553 , Diff=  16\n",
      "x1= 553 , x2= 569 , Diff=  16\n",
      "x1= 569 , x2= 592 , Diff=  23\n",
      "true: 0.0\n",
      "true: 0.02015618404390038\n",
      "true: 0.0\n",
      "false: 0.04238237490664675\n",
      "false: 0.07858009708737865\n",
      "false: 0.06489524782830863\n",
      "false: 0.03618711385701677\n",
      "false: 0.057869187531936636\n",
      "false: 0.07433252427184465\n",
      "false: 0.07691140776699029\n",
      "false: 0.07053112507138778\n",
      "false: 0.07524271844660194\n",
      "false: 0.08115898058252427\n",
      "false: 0.0723872073101085\n",
      "false: 0.07493932038834951\n",
      "false: 0.07827669902912622\n",
      "false: 0.07324386065105654\n",
      "false: 0.07842839805825243\n",
      "false: 0.07433252427184465\n",
      "false: 0.06967447173043975\n",
      "false: 0.07842839805825243\n",
      "false: 0.07190533980582524\n",
      "false: 0.06981724728726442\n",
      "false: 0.07736650485436893\n",
      "false: 0.07327063106796117\n",
      "false: 0.06424900057110222\n",
      "false: 0.056280339805825245\n",
      "false: 0.05996573386636208\n",
      "false: 0.03692787794729542\n",
      "false: 0.06310679611650485\n",
      "false: 0.06067961165048544\n",
      "false: 0.06492718446601942\n",
      "false: 0.06295509708737865\n",
      "false: 0.06492718446601942\n",
      "false: 0.03915154073448712\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from opencv_text_detection.text_detection import text_detection\n",
    "from Page_to_lines import get_lines, display_lines\n",
    "\n",
    "# Assuming you have the other necessary functions defined above\n",
    "\n",
    "for file_name in os.listdir(image_folder):\n",
    "    if file_name.endswith(\".jpg\") or file_name.endswith(\".png\"):\n",
    "        image_path = os.path.join(image_folder, file_name)\n",
    "        print(f\"Processing {image_path}\")\n",
    "\n",
    "        if \"_page\" in file_name:\n",
    "            image = cv2.imread(image_path)\n",
    "            lines = get_lines(image_path, kernel_size=17, sigma=2, theta=9, smooth_window_len=4, threshold=0.3, peak_min_distance=2)\n",
    "\n",
    "            # Create a folder for the current image\n",
    "            current_image_folder = os.path.join(output_folder, file_name[:-4])\n",
    "            if not os.path.exists(current_image_folder):\n",
    "                os.makedirs(current_image_folder)\n",
    "\n",
    "            # Process each line and save it in the folder\n",
    "            for idx, line in enumerate(lines):\n",
    "                if not line.size == 0:  # Check if the line is not empty\n",
    "                    p_line = fully_clear_background(line)\n",
    "                    if not is_line_empty(p_line):  # Check if the line contains text\n",
    "                        words_images = segment_words(line, p_line, file_name, idx)\n",
    "\n",
    "                        # Create a folder for the current line\n",
    "                        current_line_folder = os.path.join(current_image_folder, f\"line_{idx}\")\n",
    "                        if not os.path.exists(current_line_folder):\n",
    "                            os.makedirs(current_line_folder)\n",
    "\n",
    "                        for word_idx, word_image in enumerate(words_images):\n",
    "                            letters = extract_letters(word_image)\n",
    "\n",
    "                            # Create a folder for the current word\n",
    "                            current_word_folder = os.path.join(current_line_folder, f\"word_{word_idx}\")\n",
    "                            if not os.path.exists(current_word_folder):\n",
    "                                os.makedirs(current_word_folder)\n",
    "\n",
    "                            # Save each letter in the folder\n",
    "                            for letter_idx, letter_image in enumerate(letters):\n",
    "                                output_file = os.path.join(current_word_folder, f\"letter_{letter_idx}.jpg\")\n",
    "                                cv2.imwrite(output_file, letter_image)\n",
    "\n",
    "                        # Save word image in the line folder\n",
    "                        output_word_file = os.path.join(current_line_folder, f\"word_{word_idx}.jpg\")\n",
    "                        cv2.imwrite(output_word_file, word_image)\n",
    "\n",
    "                # Save line image in the image folder only if it's not empty\n",
    "                if line.size > 0:\n",
    "                    output_line_file = os.path.join(current_image_folder, f\"line_{idx}.jpg\")\n",
    "                    cv2.imwrite(output_line_file, line)\n",
    "        else:\n",
    "            data, result_img = text_detection(image_path, east_path, min_confidence, width, height)\n",
    "            output_file = os.path.join(output_folder, file_name)\n",
    "            cv2.imwrite(output_file, result_img)\n",
    "\n",
    "print(\"Processing completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
