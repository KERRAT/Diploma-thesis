{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "image_folder = \"Ukr\"\n",
    "east_path = \"opencv_text_detection/frozen_east_text_detection.pb\"\n",
    "min_confidence = 0.5\n",
    "width = 320\n",
    "height = 320\n",
    "model_path = 'UkrainianOCR/examples/Ukrainian_OCR_extended_Resnet_with_blure_and_aug.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "\n",
    "output_folder = \"tmp\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, max_size=960):\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    if height > max_size or width > max_size:\n",
    "        if height > width:\n",
    "            new_height = max_size\n",
    "            new_width = int((width * max_size) / height)\n",
    "        else:\n",
    "            new_width = max_size\n",
    "            new_height = int((height * max_size) / width)\n",
    "        return cv2.resize(image, (new_width, new_height))\n",
    "    else:\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_border(image):\n",
    "    top, bottom, left, right = 1, 1, 1, 1\n",
    "    image_without_borders = image[top:-bottom, left:-right]\n",
    "\n",
    "    image_with_border = cv2.copyMakeBorder(image_without_borders, 1, 1, 1, 1, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
    "    return image_with_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_image(image):\n",
    "    if image is None or not isinstance(image, np.ndarray) or len(image.shape) < 2:\n",
    "        raise ValueError(\"Invalid input image.\")\n",
    "\n",
    "    if len(image.shape) == 2 or image.shape[2] == 1:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    elif image.shape[2] > 3:\n",
    "        image = image[:, :, :3]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def fully_clear_background(image):\n",
    "    formated = format_image(image)\n",
    "\n",
    "    image_with_border = clear_border(formated)\n",
    "\n",
    "    gray_image = cv2.cvtColor(image_with_border, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (3, 3), 0)\n",
    "\n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 27, 50)\n",
    "    \n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def is_line_empty(line, threshold=0.03, gray_threshold=130):\n",
    "    \"\"\"\n",
    "    Determine if a line contains text based on the number of non-white pixels.\n",
    "\n",
    "    Args:\n",
    "    line (numpy.ndarray): Image of the line.\n",
    "    threshold (float): Threshold for the proportion of non-white pixels to consider a line as empty. Default is 0.01 (1%).\n",
    "    gray_threshold (int): Gray level threshold to consider a pixel as non-white. Default is 200.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the line is empty, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    non_white_pixels = np.count_nonzero(line < gray_threshold)\n",
    "    total_pixels = line.size\n",
    "\n",
    "    if non_white_pixels / total_pixels < threshold:\n",
    "        print('true:', non_white_pixels / total_pixels)\n",
    "        return True\n",
    "    else:\n",
    "        print('false:', non_white_pixels / total_pixels)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import contours\n",
    "\n",
    "def segment_words(image, p_image, file_name, line_number):\n",
    "    converted = cv2.bitwise_not(p_image)\n",
    "    \n",
    "    blurred_image = cv2.GaussianBlur(converted, (5, 5), 0)\n",
    "\n",
    "    # Apply morphological dilation to connect words\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 12))\n",
    "    dilated = cv2.dilate(blurred_image, kernel, iterations=1)\n",
    "\n",
    "    cnts = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    \n",
    "\n",
    "    words_images = []\n",
    "    if len(cnts) > 0:\n",
    "        cnts, _ = contours.sort_contours(cnts, method=\"left-to-right\")\n",
    "        \n",
    "        for c in cnts:\n",
    "            area = cv2.contourArea(c)\n",
    "            if area > 10:\n",
    "                x, y, w, h = cv2.boundingRect(c)\n",
    "                ROI = image[y:y+h, x:x+w]\n",
    "                words_images.append(ROI)\n",
    "\n",
    "    return words_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import contours\n",
    "\n",
    "\n",
    "global_max_width = 32\n",
    "global_max_height = 32\n",
    "\n",
    "def extract_letters(word_image, global_max_width, global_max_height):\n",
    "    no_border = clear_border(word_image)\n",
    "    _, otsu_threshold = cv2.threshold(no_border, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 7))\n",
    "    dilated = cv2.dilate(otsu_threshold, kernel, iterations=1)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 4))\n",
    "    eroded = cv2.erode(dilated, kernel, iterations=1)\n",
    "\n",
    "    cnts, _ = cv2.findContours(eroded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    image_copy = word_image.copy()\n",
    "    image_copy = cv2.cvtColor(image_copy, cv2.COLOR_GRAY2BGR)\n",
    "    letters = []\n",
    "\n",
    "    cnts_sorted, _ = contours.sort_contours(cnts, method=\"left-to-right\")\n",
    "\n",
    "    # Process each contour and pad the images\n",
    "    for cont in cnts_sorted:\n",
    "        x, y, w, h = cv2.boundingRect(cont)\n",
    "        if h > 0 and w > 0:\n",
    "            cv2.rectangle(image_copy, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            letter = word_image[y:y+h, x:x+w]\n",
    "            \n",
    "            thresh = cv2.adaptiveThreshold(letter, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 181, 40)\n",
    "\n",
    "            # Calculate padding for the current letter\n",
    "            pad_top = max(0, global_max_height - h)\n",
    "            pad_bottom = 2\n",
    "            pad_left = max(0, (global_max_width - w) // 2)\n",
    "            pad_right = max(0, global_max_width - w - pad_left)\n",
    "\n",
    "            # Pad the letter image to match the maximum dimensions\n",
    "            letter_padded = cv2.copyMakeBorder(thresh, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT, value=0)\n",
    "            letters.append(letter_padded)\n",
    "\n",
    "    return letters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def recognize_letter(letter_image, model):\n",
    "    letters = [\n",
    "    'А','Б','В','Г','Ґ','Д','Е','Є','Ж','З','И','І','Ї','Й','К',\n",
    "    'Л','М','Н','О','П','Р','С','Т','У','Ф','Х','Ц','Ч','Ш','Щ',\n",
    "    'Ь','Ю','Я','а','б','в','г','ґ','д','е','є','ж','з','и','і',\n",
    "    'ї','й','к','л','м','н','о','п','р','с','т','у','ф','х','ц',\n",
    "    'ч','ш','щ','ь','ю','я','1','2','3','4','5','6','7','8','9',\n",
    "    '0','№','%','@',',','.','?',':',';','\"','!','(',')','-','\\''\n",
    "    ]\n",
    "    \n",
    "\n",
    "    # Змінюємо розмір зображення літери до 32x32\n",
    "    resized_letter = cv2.resize(letter_image, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "    # Перевіряємо кількість каналів у зображенні\n",
    "    if len(resized_letter.shape) == 3:\n",
    "        # Конвертуємо зображення у відтінки сірого, якщо воно кольорове\n",
    "        gray_letter = cv2.cvtColor(resized_letter, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray_letter = resized_letter\n",
    "    \n",
    "\n",
    "    # Конвертуємо в float32 та нормалізуємо\n",
    "    data = np.array(gray_letter, dtype=np.float32)\n",
    "    data = np.expand_dims(data, axis=-1)\n",
    "    data /= 255.0\n",
    "    \n",
    "    cv2.imshow('',gray_letter)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Передбачаємо літеру за допомогою навченої моделі\n",
    "    prediction = model.predict(np.array([data]))[0]\n",
    "    predicted_index = np.argmax(prediction)\n",
    "    probability = prediction[predicted_index]  # Отримуємо ймовірність передбаченого індексу\n",
    "    \n",
    "    predicted_letter = letters[predicted_index]  # Отримуємо передбачену літеру з масиву літер\n",
    "    \n",
    "    return predicted_letter, probability, predicted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save_image(folder_path, file_name, image):\n",
    "    output_file = os.path.join(folder_path, file_name)\n",
    "    cv2.imwrite(output_file, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Ukr\\aaaFranko_page.jpg\n",
      "x1= 0 , x2= 0 , Diff=  0\n",
      "x1= 0 , x2= 10 , Diff=  10\n",
      "x1= 10 , x2= 22 , Diff=  12\n",
      "x1= 22 , x2= 51 , Diff=  29\n",
      "x1= 51 , x2= 79 , Diff=  28\n",
      "x1= 79 , x2= 107 , Diff=  28\n",
      "x1= 107 , x2= 135 , Diff=  28\n",
      "x1= 135 , x2= 163 , Diff=  28\n",
      "x1= 163 , x2= 195 , Diff=  32\n",
      "x1= 195 , x2= 236 , Diff=  41\n",
      "x1= 236 , x2= 264 , Diff=  28\n",
      "x1= 264 , x2= 292 , Diff=  28\n",
      "x1= 292 , x2= 320 , Diff=  28\n",
      "x1= 320 , x2= 348 , Diff=  28\n",
      "x1= 348 , x2= 376 , Diff=  28\n",
      "x1= 376 , x2= 404 , Diff=  28\n",
      "x1= 404 , x2= 432 , Diff=  28\n",
      "x1= 432 , x2= 459 , Diff=  27\n",
      "x1= 459 , x2= 499 , Diff=  40\n",
      "x1= 499 , x2= 532 , Diff=  33\n",
      "x1= 532 , x2= 560 , Diff=  28\n",
      "x1= 560 , x2= 587 , Diff=  27\n",
      "x1= 587 , x2= 615 , Diff=  28\n",
      "x1= 615 , x2= 642 , Diff=  27\n",
      "x1= 642 , x2= 671 , Diff=  29\n",
      "x1= 671 , x2= 722 , Diff=  51\n",
      "true: 0.0\n",
      "true: 0.0\n",
      "false: 0.04678862858647012\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\smooth.dispatch.cpp:294: error: (-215:Assertion failed) ksize.width > 0 && ksize.width % 2 == 1 && ksize.height > 0 && ksize.height % 2 == 1 in function 'cv::createGaussianKernels'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 60\u001b[0m\n\u001b[0;32m     56\u001b[0m save_image(current_word_folder, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mletter_\u001b[39m\u001b[39m{\u001b[39;00mletter_idx\u001b[39m}\u001b[39;00m\u001b[39m.jpg\u001b[39m\u001b[39m\"\u001b[39m, letter_image)\n\u001b[0;32m     58\u001b[0m \u001b[39m# Recognize the letter using the trained model                               \u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m predicted_letter, probability, predicted_index \u001b[39m=\u001b[39m recognize_letter(letter_image, model)\n\u001b[0;32m     61\u001b[0m result \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m predicted_letter\n\u001b[0;32m     62\u001b[0m save_image(letters_folder, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfile_\u001b[39m\u001b[39m{\u001b[39;00mfile_name\u001b[39m}\u001b[39;00m\u001b[39m_line_\u001b[39m\u001b[39m{\u001b[39;00mline_idx\u001b[39m}\u001b[39;00m\u001b[39m_word_\u001b[39m\u001b[39m{\u001b[39;00mword_idx\u001b[39m}\u001b[39;00m\u001b[39m_letter_\u001b[39m\u001b[39m{\u001b[39;00mletter_idx\u001b[39m}\u001b[39;00m\u001b[39m_prediction_\u001b[39m\u001b[39m{\u001b[39;00mpredicted_index\u001b[39m}\u001b[39;00m\u001b[39m.jpg\u001b[39m\u001b[39m\"\u001b[39m, letter_image)\n",
      "Cell \u001b[1;32mIn[112], line 17\u001b[0m, in \u001b[0;36mrecognize_letter\u001b[1;34m(letter_image, model)\u001b[0m\n\u001b[0;32m     15\u001b[0m blur_size \u001b[39m=\u001b[39m (\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)  \u001b[39m# розмір ядра для гаусового блюру, можна змінювати за потреби\u001b[39;00m\n\u001b[0;32m     16\u001b[0m blur_sigma \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# відхилення, якщо дорівнює 0, відхилення обчислюється автоматично\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m letter_blured \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mGaussianBlur(resized_letter, blur_size, blur_sigma)\n\u001b[0;32m     19\u001b[0m \u001b[39m# Перевіряємо кількість каналів у зображенні\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(letter_blured\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m     21\u001b[0m     \u001b[39m# Конвертуємо зображення у відтінки сірого, якщо воно кольорове\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\smooth.dispatch.cpp:294: error: (-215:Assertion failed) ksize.width > 0 && ksize.width % 2 == 1 && ksize.height > 0 && ksize.height % 2 == 1 in function 'cv::createGaussianKernels'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from opencv_text_detection.text_detection import text_detection\n",
    "from Page_to_lines import get_lines, display_lines\n",
    "\n",
    "# Assuming you have the other necessary functions defined above\n",
    "\n",
    "for file_name in os.listdir(image_folder):\n",
    "    if file_name.endswith(\".jpg\") or file_name.endswith(\".png\"):\n",
    "        image_path = os.path.join(image_folder, file_name)\n",
    "        print(f\"Processing {image_path}\")\n",
    "\n",
    "        if \"_page\" in file_name:\n",
    "            result = ''\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            # Resize the image before processing\n",
    "            resized_image = resize_image(image)\n",
    "\n",
    "            # Save the resized image, overwriting the original image\n",
    "            cv2.imwrite(image_path, resized_image)\n",
    "            \n",
    "            lines = get_lines(image_path, kernel_size=17, sigma=2, theta=9, smooth_window_len=4, threshold=0.3, peak_min_distance=2)\n",
    "\n",
    "            # Create a folder for the current image\n",
    "            current_image_folder = os.path.join(output_folder, file_name[:-4])\n",
    "            if not os.path.exists(current_image_folder):\n",
    "                os.makedirs(current_image_folder)\n",
    "\n",
    "            # Process each line and save it in the folder\n",
    "            for line_idx, line in enumerate(lines):\n",
    "                if not line.size == 0:  # Check if the line is not empty\n",
    "                    p_line = fully_clear_background(line)\n",
    "                    if not is_line_empty(p_line):  # Check if the line contains text\n",
    "                        words_images = segment_words(line, p_line, file_name, line_idx)\n",
    "                        \n",
    "                        # Create a folder for the current line\n",
    "                        current_line_folder = os.path.join(current_image_folder, f\"line_{line_idx}\")\n",
    "                        if not os.path.exists(current_line_folder):\n",
    "                            os.makedirs(current_line_folder)\n",
    "\n",
    "                        for word_idx, word_image in enumerate(words_images):\n",
    "\n",
    "                            letters = extract_letters(word_image,global_max_width, global_max_height)\n",
    "\n",
    "                            # Create a folder for the current word\n",
    "                            current_word_folder = os.path.join(current_line_folder, f\"word_{word_idx}\")\n",
    "                            if not os.path.exists(current_word_folder):\n",
    "                                os.makedirs(current_word_folder)\n",
    "                                \n",
    "                            letters_folder = os.path.join(output_folder, f\"letters\")\n",
    "                            if not os.path.exists(letters_folder):\n",
    "                                os.makedirs(letters_folder)\n",
    "                            \n",
    "                            # Save each letter in the folder\n",
    "                            for letter_idx, letter_image in enumerate(letters):\n",
    "                                save_image(current_word_folder, f\"letter_{letter_idx}.jpg\", letter_image)\n",
    "                                \n",
    "                                # Recognize the letter using the trained model                               \n",
    "\n",
    "                                predicted_letter, probability, predicted_index = recognize_letter(letter_image, model)\n",
    "                                result += predicted_letter\n",
    "                                save_image(letters_folder, f\"file_{file_name}_line_{line_idx}_word_{word_idx}_letter_{letter_idx}_prediction_{predicted_index}.jpg\", letter_image)\n",
    "                                print(f\"Letter {letter_idx} is recognized as '{predicted_letter}' with probability {probability:.2f}\")\n",
    "                                \n",
    "                            # Add space after each word\n",
    "                            result += ' '\n",
    "                            \n",
    "                            # Save word image in the line folder\n",
    "                            save_image(current_line_folder, f\"word_{word_idx}.jpg\", word_image)\n",
    "\n",
    "                # Save line image in the image folder only if it's not empty\n",
    "                if line.size > 0:\n",
    "                    save_image(current_image_folder, f\"line_{line_idx}.jpg\", line)\n",
    "\n",
    "            # Add space after each line\n",
    "            result += ' '\n",
    "            \n",
    "            print(result)\n",
    "        else:\n",
    "            data, result_img = text_detection(image_path, east_path, min_confidence, width, height)\n",
    "            save_image(output_folder, file_name, result_img)\n",
    "\n",
    "print(\"Processing completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
