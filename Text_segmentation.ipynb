{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "image_folder = \"Ukr\"\n",
    "east_path = \"text_detection/frozen_east_text_detection.pb\"\n",
    "min_confidence = 0.5\n",
    "width = 320\n",
    "height = 320\n",
    "\n",
    "output_folder = \"tmp\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "  \n",
    "  \n",
    "\n",
    "def noise_removal(image):\n",
    "  import numpy as np\n",
    "  kernel = np.ones((1,1),np.uint8)\n",
    "  image = cv2.dilate(image, kernel, iterations=1)\n",
    "  kernel = np.ones((1,1),np.uint8)\n",
    "  image = cv2.erode(image, kernel, iterations=1)    \n",
    "  image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel, iterations=4)\n",
    "  image = cv2.medianBlur(image, 3)\n",
    "  return (image)\n",
    "\n",
    "def illumination_removal(image):\n",
    "  se=cv2.getStructuringElement(cv2.MORPH_RECT , (8,8))\n",
    "  bg=cv2.morphologyEx(image, cv2.MORPH_DILATE, se)\n",
    "  out_gray=cv2.divide(image, bg, scale=255)\n",
    "  return out_gray\n",
    "\n",
    "def getSkewAngle(cvImage) -> float:\n",
    "  # Prep image, copy, convert to gray scale, blur, and threshold\n",
    "  newImage = cvImage.copy()\n",
    "  gray = cv2.cvtColor(newImage, cv2.COLOR_BGR2GRAY)\n",
    "  blur = cv2.GaussianBlur(gray, (9, 9), 0)\n",
    "  thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "  # Apply dilate to merge text into meaningful lines/paragraphs.\n",
    "  # Use larger kernel on X axis to merge characters into single line, cancelling out any spaces.\n",
    "  # But use smaller kernel on Y axis to separate between different blocks of text\n",
    "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))\n",
    "  dilate = cv2.dilate(thresh, kernel, iterations=2)\n",
    "\n",
    "  # Find all contours\n",
    "  contours, hierarchy = cv2.findContours(dilate, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  contours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "  for c in contours:\n",
    "      rect = cv2.boundingRect(c)\n",
    "      x,y,w,h = rect\n",
    "      cv2.rectangle(newImage,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "  # Find largest contour and surround in min area box\n",
    "  largestContour = contours[0]\n",
    "  print (len(contours))\n",
    "  minAreaRect = cv2.minAreaRect(largestContour)\n",
    "  cv2.imwrite(\"temp/boxes.jpg\", newImage)\n",
    "  # Determine the angle. Convert it to the value that was originally used to obtain skewed image\n",
    "  angle = minAreaRect[-1]\n",
    "  if angle < -45:\n",
    "      angle = 90 + angle\n",
    "  return -1.0 * angle\n",
    "# Rotate the image around its center\n",
    "def rotateImage(cvImage, angle: float):\n",
    "  newImage = cvImage.copy()\n",
    "  (h, w) = newImage.shape[:2]\n",
    "  center = (w // 2, h // 2)\n",
    "  M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "  newImage = cv2.warpAffine(newImage, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "  return newImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_img(img):\n",
    "  # convert to grayscale\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  # blur\n",
    "  blur = cv2.GaussianBlur(gray, (0,0), sigmaX=33, sigmaY=33)\n",
    "\n",
    "  # divide\n",
    "  divide = cv2.divide(gray, blur, scale=255)\n",
    "\n",
    "  # otsu threshold\n",
    "  thresh = cv2.threshold(divide, 160, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "\n",
    "  # apply morphology\n",
    "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,1))\n",
    "  morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "  rgb_img = cv2.cvtColor(morph, cv2.COLOR_GRAY2RGB)\n",
    "  return rgb_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_letters(image, word_image):\n",
    "    thresh = cv2.threshold(word_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 25))\n",
    "    detected_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel, iterations=1)\n",
    "    \n",
    "    cv2.imshow('Thresh', thresh)\n",
    "    cv2.imshow('Detected Lines', detected_lines)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    cnts = cv2.findContours(detected_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    letters = []\n",
    "    for c in cnts:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        letter = word_image[y:y+h, x:x+w]\n",
    "        letters.append((x, y, w, h, letter))\n",
    "\n",
    "    return letters if letters else [(0, 0, 0, 0, word_image)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Ukr\\Franko_page.jpg\n",
      "x1= 0 , x2= 0 , Diff=  0\n",
      "x1= 0 , x2= 10 , Diff=  10\n",
      "x1= 10 , x2= 22 , Diff=  12\n",
      "x1= 22 , x2= 51 , Diff=  29\n",
      "x1= 51 , x2= 79 , Diff=  28\n",
      "x1= 79 , x2= 107 , Diff=  28\n",
      "x1= 107 , x2= 135 , Diff=  28\n",
      "x1= 135 , x2= 163 , Diff=  28\n",
      "x1= 163 , x2= 195 , Diff=  32\n",
      "x1= 195 , x2= 236 , Diff=  41\n",
      "x1= 236 , x2= 264 , Diff=  28\n",
      "x1= 264 , x2= 292 , Diff=  28\n",
      "x1= 292 , x2= 320 , Diff=  28\n",
      "x1= 320 , x2= 348 , Diff=  28\n",
      "x1= 348 , x2= 376 , Diff=  28\n",
      "x1= 376 , x2= 404 , Diff=  28\n",
      "x1= 404 , x2= 432 , Diff=  28\n",
      "x1= 432 , x2= 459 , Diff=  27\n",
      "x1= 459 , x2= 499 , Diff=  40\n",
      "x1= 499 , x2= 532 , Diff=  33\n",
      "x1= 532 , x2= 560 , Diff=  28\n",
      "x1= 560 , x2= 587 , Diff=  27\n",
      "x1= 587 , x2= 615 , Diff=  28\n",
      "x1= 615 , x2= 642 , Diff=  27\n",
      "x1= 642 , x2= 671 , Diff=  29\n",
      "x1= 671 , x2= 722 , Diff=  51\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:  \u001b[39m# Check if the line is not empty\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     line_copy \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m---> 24\u001b[0m     words \u001b[39m=\u001b[39m segment_words(line_copy, line)\n\u001b[0;32m     25\u001b[0m     display_segments(line_copy, words, \u001b[39m\"\u001b[39m\u001b[39mWords\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m     \u001b[39mfor\u001b[39;00m word_index, (_, _, _, _, word_image) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(words):\n",
      "Cell \u001b[1;32mIn[40], line 9\u001b[0m, in \u001b[0;36msegment_words\u001b[1;34m(image, line_image)\u001b[0m\n\u001b[0;32m      7\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mThresh\u001b[39m\u001b[39m'\u001b[39m, thresh)\n\u001b[0;32m      8\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mDetected Lines\u001b[39m\u001b[39m'\u001b[39m, detected_lines)\n\u001b[1;32m----> 9\u001b[0m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     10\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     12\u001b[0m cnts \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mfindContours(detected_lines, cv2\u001b[39m.\u001b[39mRETR_EXTERNAL, cv2\u001b[39m.\u001b[39mCHAIN_APPROX_SIMPLE)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from text_detection.text_detection import text_detection\n",
    "\n",
    "from Page_to_lines import get_lines, display_lines\n",
    "\n",
    "for file_name in os.listdir(image_folder):\n",
    "  if file_name.endswith(\".jpg\") or file_name.endswith(\".png\"):\n",
    "    image_path = os.path.join(image_folder, file_name)\n",
    "    print(f\"Processing {image_path}\")\n",
    "\n",
    "    if \"_page\" in file_name:\n",
    "        image = cv2.imread(image_path)\n",
    "        lines = get_lines(image_path, kernel_size = 17, sigma=2, theta=9, smooth_window_len=4, threshold=0.3, peak_min_distance=2)\n",
    "\n",
    "        # Create a folder for the current image\n",
    "        current_image_folder = os.path.join(output_folder, file_name[:-4])\n",
    "        if not os.path.exists(current_image_folder):\n",
    "            os.makedirs(current_image_folder)\n",
    "\n",
    "        # Process each line and save it in the folder\n",
    "        for idx, line in enumerate(lines):\n",
    "            if not line.size == 0:  # Check if the line is not empty\n",
    "                line = cv2.cvtColor(line, cv2.COLOR_GRAY2RGB)\n",
    "                output_file = os.path.join(current_image_folder, f\"line_{idx}.jpg\")\n",
    "                cv2.imwrite(output_file, line)\n",
    "    else:\n",
    "        data, result_img = text_detection(image_path, east_path, min_confidence, width, height)\n",
    "        output_file = os.path.join(output_folder, file_name)\n",
    "        cv2.imwrite(output_file, result_img)\n",
    "\n",
    "print(\"Processing completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
